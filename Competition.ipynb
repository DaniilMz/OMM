{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaniilMz/OMM/blob/main/Competition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import onnx\n",
        "import onnx.helper as helper\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from typing import Tuple, List, Optional, Dict, Any"
      ],
      "metadata": {
        "id": "f7wxd8cdiRKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_parquet(\"./competition_package/datasets/train.parquet\")\n",
        "eval_data = pd.read_parquet(\"./competition_package/datasets/valid.parquet\")\n",
        "\n",
        "train_data[['t0', 't1']] = train_data[['t0', 't1']] / 100\n",
        "eval_data[['t0', 't1']] = eval_data[['t0', 't1']] / 100"
      ],
      "metadata": {
        "id": "DJg_sgsnEIEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_features = [col for col in train_data.columns if col.startswith('p')]\n",
        "v_features = [col for col in train_data.columns if col.startswith('v')]\n",
        "dp_features = [col for col in train_data.columns if col.startswith('dp')]\n",
        "dv_features = [col for col in train_data.columns if col.startswith('dv')]\n",
        "\n",
        "all_features = p_features + v_features + dp_features + dv_features\n",
        "\n",
        "targets = ['t0', 't1']"
      ],
      "metadata": {
        "id": "oK3FIBI4ELeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Основной функционал"
      ],
      "metadata": {
        "id": "MBpKLoCPEeUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_columns() -> List[str]:\n",
        "    cols = []\n",
        "    for prefix in (\"p\", \"v\"):\n",
        "        cols += [f\"{prefix}{i}\" for i in range(12)]\n",
        "    for prefix in (\"dp\", \"dv\"):\n",
        "        cols += [f\"{prefix}{i}\" for i in range(4)]\n",
        "    return cols\n",
        "\n",
        "\n",
        "def target_columns() -> List[str]:\n",
        "    return [\"t0\", \"t1\"]\n",
        "\n",
        "\n",
        "def df_to_numpy_arrays(\n",
        "    df: pd.DataFrame,\n",
        "    seq_col: str = \"seq_ix\",\n",
        "    step_col: str = \"step_in_seq\",\n",
        "    need_pred_col: str = \"need_prediction\",\n",
        ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Преобразует DataFrame в три numpy массива:\n",
        "    X: (N_seq, T, F) dtype=float32\n",
        "    Y: (N_seq, T, 2) dtype=float32\n",
        "    mask: (N_seq, T) dtype=float32 (0/1 — use for loss)\n",
        "    Требуется, чтобы все последовательности имели одинаковую длину T и\n",
        "    шаги были 0..T-1 (или были упорядочены).\n",
        "    \"\"\"\n",
        "    feat_cols = feature_columns()\n",
        "    targ_cols = target_columns()\n",
        "\n",
        "    df_sorted = df.sort_values([seq_col, step_col], kind=\"stable\")\n",
        "\n",
        "    seq_ids = df_sorted[seq_col].to_numpy()\n",
        "    unique_seq_ids, counts = np.unique(seq_ids, return_counts=True)\n",
        "    N_seq = len(unique_seq_ids)\n",
        "    if counts.min() != counts.max():\n",
        "        raise ValueError(\"Ожидается что все последовательности одной длины (T).\")\n",
        "    T = counts[0]\n",
        "\n",
        "    X_all = df_sorted[feat_cols].to_numpy(dtype=np.float32)\n",
        "    X = X_all.reshape(N_seq, T, len(feat_cols))\n",
        "    X = np.ascontiguousarray(X)\n",
        "\n",
        "    Y_all = df_sorted[targ_cols].to_numpy(dtype=np.float32)\n",
        "    Y = Y_all.reshape(N_seq, T, len(targ_cols))\n",
        "    Y = np.ascontiguousarray(Y)\n",
        "\n",
        "    mask_all = df_sorted[need_pred_col].to_numpy(dtype=np.uint8)\n",
        "    mask = mask_all.reshape(N_seq, T)\n",
        "    mask = np.ascontiguousarray(mask)\n",
        "    return X, Y, mask"
      ],
      "metadata": {
        "id": "5K0Olc4REOOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset возвращает целиком одну последовательность:\n",
        "    X: (T, F)\n",
        "    Y: (T, 2)\n",
        "    mask: (T,)\n",
        "    Все в torch.float32 на CPU (torch.from_numpy без копирования, если входные массивы contiguous).\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        X_np: np.ndarray,\n",
        "        Y_np: np.ndarray,\n",
        "        mask_np: np.ndarray,\n",
        "        precompute_weights: bool = True,\n",
        "        eps: float = 1e-8\n",
        "    ):\n",
        "        assert X_np.ndim == 3\n",
        "        assert Y_np.ndim == 3\n",
        "        assert mask_np.ndim == 2\n",
        "        self.X = X_np\n",
        "        self.Y = Y_np\n",
        "        self.mask = mask_np\n",
        "        self.eps = eps\n",
        "        if precompute_weights:\n",
        "            w = np.abs(self.Y)\n",
        "            w = np.maximum(w, float(eps))\n",
        "            self.weights = np.ascontiguousarray(w.astype(np.float32))\n",
        "        else:\n",
        "            self.weights = None\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.from_numpy(self.X[idx])  # (T, F)\n",
        "        y = torch.from_numpy(self.Y[idx])  # (T, 2)\n",
        "        mask = torch.from_numpy(self.mask[idx])  # (T,)\n",
        "        if self.weights is not None:\n",
        "            w = torch.from_numpy(self.weights[idx])  # (T,2)\n",
        "        else:\n",
        "            w = None\n",
        "        return x, y, mask, w\n",
        "\n",
        "\n",
        "def make_dataloader(\n",
        "    dataset: Dataset,\n",
        "    batch_size: int = 64,\n",
        "    shuffle: bool = True,\n",
        "    num_workers: int = 4,\n",
        "    pin_memory: bool = True,\n",
        "    persistent_workers: bool = True,\n",
        "    prefetch_factor: int = 2,\n",
        ") -> DataLoader:\n",
        "    \"\"\"\n",
        "    Рекомендуемые параметры:\n",
        "    - num_workers: 2..8 (зависит от CPU и диска)\n",
        "    - pin_memory=True (если GPU)\n",
        "    - persistent_workers=True (ускоряет при частых epoch)\n",
        "    - prefetch_factor: 2..4\n",
        "    \"\"\"\n",
        "    dl = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        persistent_workers=persistent_workers, # при повторном итерировании работает быстрее (однако походу перестает работать shuffle; использовать generator + worker_init_fn)\n",
        "        prefetch_factor=prefetch_factor, # каждый воркер обрабатывает prefetch_factor*batch_size примеров\n",
        "    )\n",
        "    return dl"
      ],
      "metadata": {
        "id": "1ZJTVW1JEj-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_weighted_pearson_torch(y_true: torch.Tensor,\n",
        "                                 y_pred: torch.Tensor,\n",
        "                                 mask: torch.Tensor,\n",
        "                                 weights: Optional[torch.Tensor] = None,\n",
        "                                 clip_value: float = 6.0, # как в примере\n",
        "                                 eps: float = 1e-8) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Вытягиваем последовательности внутри батча и считаем корреляцию.\n",
        "    y_true, y_pred: (B,T,C)\n",
        "    mask: (B,T) 0/1\n",
        "    weights: (B,T,C) optional; if None -> use abs(y_true) as in scorer\n",
        "    Returns:\n",
        "    corr_per_channel (C,), mean_abs_corr scalar\n",
        "    \"\"\"\n",
        "    B, T, C = y_true.shape\n",
        "    device = y_true.device\n",
        "    dtype = y_true.dtype\n",
        "\n",
        "    # Flatten valid points inside batch\n",
        "    m = mask.unsqueeze(-1)  # (B,T,1)\n",
        "    valid_mask = (m > 0).reshape(-1)  # (B*T,); маска вида: 100 False, 900 True, 100 False, 900 True, ...\n",
        "    if valid_mask.sum() == 0:\n",
        "        corr = torch.zeros(C, device=device, dtype=dtype)\n",
        "        return corr, torch.tensor(0.0, device=device, dtype=dtype)\n",
        "\n",
        "    y = y_true.reshape(-1, C)[valid_mask]  # (B*T, C) # также вытягиваем вдоль батча\n",
        "    yhat = y_pred.reshape(-1, C)[valid_mask]\n",
        "\n",
        "    # clip predictions as in scorer\n",
        "    yhat = torch.clamp(yhat, -clip_value, clip_value)\n",
        "\n",
        "    if weights is None:\n",
        "        w = torch.abs(y)\n",
        "    else:\n",
        "        w = weights.reshape(-1, C)[valid_mask]\n",
        "    # floor weights\n",
        "    w = torch.maximum(w, torch.tensor(eps, device=device, dtype=dtype))\n",
        "\n",
        "    sum_w = w.sum(dim=0).clamp_min(eps)  # (C,)\n",
        "\n",
        "    mean_y = (w * y).sum(dim=0) / sum_w\n",
        "    mean_yhat = (w * yhat).sum(dim=0) / sum_w\n",
        "\n",
        "    y_c = y - mean_y.unsqueeze(0)\n",
        "    yhat_c = yhat - mean_yhat.unsqueeze(0)\n",
        "\n",
        "    cov = (w * y_c * yhat_c).sum(dim=0) / sum_w\n",
        "    var_y = (w * y_c * y_c).sum(dim=0) / sum_w\n",
        "    var_yhat = (w * yhat_c * yhat_c).sum(dim=0) / sum_w\n",
        "\n",
        "    denom = torch.sqrt(var_y * var_yhat).clamp_min(eps)\n",
        "    corr = cov / denom\n",
        "    corr = torch.clamp(corr, -1.0, 1.0)\n",
        "    # mean_abs_corr = corr.abs().mean() # тут берем модуль от коэффициента корреляции, это будто бы лишнее\n",
        "    mean_abs_corr = corr.mean()\n",
        "    return corr, mean_abs_corr\n",
        "\n",
        "# -------------------------\n",
        "# 5) Combined loss (MSE + (- |corr|)), computed batch-wise with flattening inside batch\n",
        "# -------------------------\n",
        "class CombinedLoss(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 alpha: float = 1.0,\n",
        "                 beta: float = 1.0,\n",
        "                 clip_value: float = 6.0,\n",
        "                 eps: float = 1e-8,\n",
        "                 weight_gamma: float = 1.0,\n",
        "                 max_weight: Optional[float] = None):\n",
        "        \"\"\"\n",
        "        weight_gamma: exponent for weight transform: w = |y|**gamma\n",
        "        max_weight: if not None, cap weights at this value\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.clip_value = float(clip_value)\n",
        "        self.eps = float(eps)\n",
        "        self.gamma = float(weight_gamma)\n",
        "        self.max_weight = float(max_weight) if max_weight is not None else None\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                y_pred: torch.Tensor,  # (B,T,C)\n",
        "                y_true: torch.Tensor,  # (B,T,C)\n",
        "                mask: torch.Tensor,  # (B,T)\n",
        "                weights: Optional[torch.Tensor] = None  # optional (B,T,C)\n",
        "                ) -> Tuple[torch.Tensor, Dict[str, Any]]:\n",
        "\n",
        "        device = y_true.device\n",
        "        dtype = y_true.dtype\n",
        "        B, T, C = y_true.shape\n",
        "\n",
        "        # ----- Weighted MSE -----\n",
        "        # if external weights provided, use them; else use amplitude-based weights |y|**gamma (веса возводим в некоторую степень; мб это лучше делать только для mse, а может и нет)\n",
        "        if weights is None:\n",
        "            w = torch.abs(y_true).pow(self.gamma)  # (B,T,C)\n",
        "        else:\n",
        "            w = weights.clone()\n",
        "            if self.gamma != 1.0:\n",
        "                w = w.pow(self.gamma)\n",
        "\n",
        "        # floor and cap\n",
        "        w = torch.maximum(w, torch.tensor(self.eps, device=device, dtype=dtype))\n",
        "        if self.max_weight is not None:\n",
        "            w = torch.minimum(w, torch.tensor(self.max_weight, device=device, dtype=dtype))\n",
        "\n",
        "        # apply mask (zero-out warmup)\n",
        "        m = mask.unsqueeze(-1)  # (B,T,1)\n",
        "        w = w * m  # (B,T,C)\n",
        "\n",
        "        # normalize per channel within batch (to make loss scale stable)\n",
        "        sum_w = w.sum(dim=(0, 1)).clamp_min(self.eps)  # (C,); суммируем по батчу и по всем шагам в последовательности\n",
        "        # weighted MSE per channel\n",
        "        diff2 = (y_pred - y_true).pow(2) * w  # (B,T,C)\n",
        "        mse_per_ch = diff2.sum(dim=(0, 1)) / sum_w  # (C,)\n",
        "        mse_mean = mse_per_ch.mean()\n",
        "\n",
        "        # ----- Pearson term (batch flattened) -----\n",
        "        corr_per_ch, mean_abs_corr = batch_weighted_pearson_torch(\n",
        "            y_true, y_pred, mask, weights=w, clip_value=self.clip_value, eps=self.eps\n",
        "        )\n",
        "\n",
        "        term_mse = mse_mean\n",
        "        term_corr = - mean_abs_corr\n",
        "\n",
        "        loss = self.alpha * term_mse + self.beta * term_corr\n",
        "\n",
        "        info = {\n",
        "            \"loss\": float(loss.detach().cpu()), # alpha*mse_mean - beta*mean_abs_corr\n",
        "            \"mse_mean\": float(mse_mean.detach().cpu()), # среднее по 2 таргетам mse, np.mean(mse_per_ch) (мб надо тоже с весами усреднять)\n",
        "            \"mse_per_ch\": mse_per_ch.detach().cpu().tolist(), # средневзвеш. mse по каждому из таргетов\n",
        "            \"corr_per_ch\": corr_per_ch.detach().cpu().tolist(), # взвешенные модули коэф. корреляции по каждому из таргетов\n",
        "            \"mean_abs_corr\": float(mean_abs_corr.detach().cpu()), # среднее значение взвешенных модулей коэф. корреляции по каждому из таргетов\n",
        "            \"term_mse\": float(term_mse.detach().cpu()), # аналогично mse_mean\n",
        "            \"term_corr\": float(term_corr.detach().cpu()), # аналогично -mean_abs_corr\n",
        "        }\n",
        "        return loss, info\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 6) Numpy scorer (exact copy of user's numpy scorer) for eval\n",
        "# -------------------------\n",
        "def weighted_pearson_correlation_np(y_true: np.ndarray, y_pred: np.ndarray, clip_value: float = 6.0, eps: float = 1e-8) -> float:\n",
        "    y_pred_clipped = np.clip(y_pred, -clip_value, clip_value)\n",
        "    weights = np.abs(y_true)\n",
        "    weights = np.maximum(weights, eps)\n",
        "\n",
        "    sum_w = np.sum(weights)\n",
        "    if sum_w == 0:\n",
        "        return 0.0\n",
        "\n",
        "    mean_true = np.sum(y_true * weights) / sum_w\n",
        "    mean_pred = np.sum(y_pred_clipped * weights) / sum_w\n",
        "\n",
        "    dev_true = y_true - mean_true\n",
        "    dev_pred = y_pred_clipped - mean_pred\n",
        "\n",
        "    cov = np.sum(weights * dev_true * dev_pred) / sum_w\n",
        "    var_true = np.sum(weights * dev_true**2) / sum_w\n",
        "    var_pred = np.sum(weights * dev_pred**2) / sum_w\n",
        "\n",
        "    if var_true <= 0 or var_pred <= 0:\n",
        "        return 0.0\n",
        "\n",
        "    corr = cov / (np.sqrt(var_true) * np.sqrt(var_pred))\n",
        "    return float(corr)\n",
        "\n",
        "\n",
        "def calc_global_np_score(preds_all: np.ndarray, targets_all: np.ndarray, clip_value: float = 6.0) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    preds_all, targets_all: (N_total, C)\n",
        "    returns dict with per-target weighted pearson and avg\n",
        "    \"\"\"\n",
        "    C = preds_all.shape[1]\n",
        "    scores = {}\n",
        "    for c in range(C):\n",
        "        scores[f\"t{c+1}\"] = weighted_pearson_correlation_np(targets_all[:, c], preds_all[:, c], clip_value=clip_value)\n",
        "    scores[\"weighted_pearson\"] = float(np.mean(list(scores.values())))\n",
        "    return scores"
      ],
      "metadata": {
        "id": "oOuL8R6wEm9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(\n",
        "    model: nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    loss_fn: CombinedLoss,\n",
        "    device: torch.device,\n",
        "    scaler: Optional[torch.cuda.amp.GradScaler] = None,\n",
        "    grad_clip: Optional[float] = 1.0,\n",
        "    accum_steps: int = 1,\n",
        ") -> Dict[str, Any]:\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    batches = 0\n",
        "    # accumulators for logging\n",
        "    mse_means = []\n",
        "    corr_means = []\n",
        "    corr_by_ch_means = []\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    for step, batch in enumerate(tqdm(dataloader, desc=\"train\", leave=False)):\n",
        "        X, Y, mask, weights = batch  # X:(B,T,F), Y:(B,T,2), mask:(B,T), weights:(B,T,2) or None\n",
        "        X = X.to(device, non_blocking=True)\n",
        "        Y = Y.to(device, non_blocking=True)\n",
        "        mask = mask.to(device, non_blocking=True)\n",
        "        if weights is not None:\n",
        "            weights = weights.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(scaler is not None)): # автоматич. управление численной точностью; нужен scaler (torch.cuda.amp.GradScaler)\n",
        "            preds, _ = model(X)\n",
        "            loss, info = loss_fn(preds, Y, mask, weights)\n",
        "\n",
        "        loss_value = loss / accum_steps # связано с расчетами в смешанной точности\n",
        "\n",
        "        if scaler is None:\n",
        "            loss_value.backward()\n",
        "            if (step + 1) % accum_steps == 0:\n",
        "                if grad_clip is not None:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "        else:\n",
        "            scaler.scale(loss_value).backward()\n",
        "            if (step + 1) % accum_steps == 0:\n",
        "                if grad_clip is not None:\n",
        "                    scaler.unscale_(optimizer)\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        total_loss += float(loss.detach().cpu())\n",
        "        mse_means.append(info[\"mse_mean\"])\n",
        "        corr_means.append(info[\"mean_abs_corr\"])\n",
        "        corr_by_ch_means.append(info[\"corr_per_ch\"])\n",
        "        batches += 1\n",
        "\n",
        "\n",
        "    stats = {\n",
        "        \"train_loss\": total_loss / max(1, batches), # средний лосс по батчам: 1/N * sum{i_1N} loss_i\n",
        "        \"train_mse_mean\": float(np.mean(mse_means)) if len(mse_means) else 0.0, # средняя компонента mse лосса по батчам\n",
        "        \"train_mean_abs_corr\": float(np.mean(corr_means)) if len(corr_means) else 0.0, # среднее значение коэффициента корреляции по батчам\n",
        "        'train_mean_corr_by_ch': np.mean(corr_by_ch_means, axis=0).tolist() if len(corr_by_ch_means) else [0.0, 0.0],\n",
        "        \"batches\": batches\n",
        "    }\n",
        "    return stats\n",
        "\n",
        "\n",
        "def eval_one_epoch(\n",
        "    model: nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    loss_fn: CombinedLoss,\n",
        "    device: torch.device,\n",
        "    clip_value: float = 6.0,\n",
        ") -> Dict[str, Any]:\n",
        "    model.eval()\n",
        "    batch_mse_list = []\n",
        "    batch_corr_list = []\n",
        "    total_loss = 0.0\n",
        "    batches = 0\n",
        "    preds_list = []\n",
        "    targets_list = []\n",
        "    masks_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"eval\", leave=False):\n",
        "            X, Y, mask, weights = batch\n",
        "            X = X.to(device, non_blocking=True)\n",
        "            Y = Y.to(device, non_blocking=True)\n",
        "            mask = mask.to(device, non_blocking=True)\n",
        "            if weights is not None:\n",
        "                weights = weights.to(device, non_blocking=True)\n",
        "\n",
        "            preds, _ = model(X)\n",
        "            loss, info = loss_fn(preds, Y, mask, weights)\n",
        "\n",
        "            total_loss += float(loss.detach().cpu())\n",
        "            batches += 1\n",
        "\n",
        "            batch_mse_list.append(info.get(\"mse_mean\", 0.0))\n",
        "            batch_corr_list.append(info.get(\"mean_abs_corr\", 0.0))\n",
        "\n",
        "            preds_list.append(preds.detach().cpu().numpy())\n",
        "            targets_list.append(Y.detach().cpu().numpy())\n",
        "            masks_list.append(mask.detach().cpu().numpy())\n",
        "\n",
        "    # compute batchwise-averaged diagnostics\n",
        "    val_mse_mean = float(np.mean(batch_mse_list)) if batch_mse_list else 0.0\n",
        "    val_mean_abs_corr_batchwise = float(np.mean(batch_corr_list)) if batch_corr_list else 0.0\n",
        "    val_loss = total_loss / max(1, batches)\n",
        "\n",
        "    preds_all = np.concatenate(preds_list, axis=0) if preds_list else np.empty((0,0,0))\n",
        "    targets_all = np.concatenate(targets_list, axis=0) if targets_list else np.empty((0,0,0))\n",
        "    masks_all = np.concatenate(masks_list, axis=0) if masks_list else np.empty((0,0))\n",
        "\n",
        "    # Now create 2D arrays of valid points by flattening batch axis and time\n",
        "    if preds_all.size == 0:\n",
        "        global_scores = {\"t1\": 0.0, \"t2\": 0.0, \"weighted_pearson\": 0.0}\n",
        "    else:\n",
        "        B_total, T, C = preds_all.shape\n",
        "        preds_flat = preds_all.reshape(-1, C)\n",
        "        targets_flat = targets_all.reshape(-1, C)\n",
        "        masks_flat = masks_all.reshape(-1)\n",
        "        valid_idx = masks_flat > 0\n",
        "        if valid_idx.sum() == 0:\n",
        "            global_scores = {\"t1\": 0.0, \"t2\": 0.0, \"weighted_pearson\": 0.0}\n",
        "        else:\n",
        "            preds_valid = preds_flat[valid_idx]\n",
        "            targets_valid = targets_flat[valid_idx]\n",
        "            # global_scores = calc_global_np_score(preds_valid, targets_valid, clip_value=clip_value) # вытянули все последовательности и считаем метрику соревнования\n",
        "\n",
        "            per_target_corrs = []\n",
        "            for ch in range(C):\n",
        "                per_target_corrs.append(\n",
        "                    weighted_pearson_correlation_np(targets_valid[:, ch], preds_valid[:, ch], clip_value=clip_value)\n",
        "                )\n",
        "            weighted_pearson = float(np.mean(per_target_corrs))\n",
        "\n",
        "            # also compute global weighted MSE (same weights as correlation: w=|y|)\n",
        "            weights = np.maximum(np.abs(targets_valid), 1e-8)\n",
        "            sum_w = weights.sum(axis=0)\n",
        "            # avoid division by zero\n",
        "            mse_per_ch = []\n",
        "            for ch in range(C):\n",
        "                w = weights[:, ch]\n",
        "                denom = sum_w[ch] if sum_w[ch] > 0 else 1.0\n",
        "                mse_ch = np.sum(w * (preds_valid[:, ch] - targets_valid[:, ch])**2) / denom\n",
        "                mse_per_ch.append(mse_ch)\n",
        "            global_mse = float(np.mean(mse_per_ch))\n",
        "\n",
        "            global_scores = {f\"t{ch+1}\": per_target_corrs[ch] for ch in range(C)}\n",
        "            global_scores[\"weighted_pearson\"] = weighted_pearson # метрика соревнования\n",
        "            global_scores[\"global_mse\"] = global_mse # mse, посчитанное на всей валидационной выборке\n",
        "\n",
        "    stats = {\n",
        "        \"val_loss\": val_loss, # средний по батчам лосс\n",
        "        \"val_mse_mean\": val_mse_mean,  # batchwise average MSE (среднее по батчам mse)\n",
        "        \"val_mean_abs_corr_batchwise\": val_mean_abs_corr_batchwise,  # batchwise average corr (средний по батчам коэффициент корреляции)\n",
        "    }\n",
        "    stats.update(global_scores)\n",
        "\n",
        "    return stats\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 8) fit function\n",
        "# -------------------------\n",
        "# def fit(\n",
        "#     model: nn.Module,\n",
        "#     train_loader: DataLoader,\n",
        "#     val_loader: DataLoader,\n",
        "#     device: torch.device,\n",
        "#     num_epochs: int = 30,\n",
        "#     lr: float = 1e-3,\n",
        "#     weight_decay: float = 1e-5,\n",
        "#     alpha: float = 1.0,\n",
        "#     beta: float = 1.0,\n",
        "#     weight_gamma: float = 1.0,\n",
        "#     grad_clip: float = 1.0,\n",
        "#     accum_steps: int = 1,\n",
        "#     use_amp: bool = True,\n",
        "#     save_path: str = \"best_model.pt\",\n",
        "#     monitor: str = \"weighted_pearson\",  # metric from eval_one_epoch to maximize\n",
        "#     maximize_monitor: bool = True,\n",
        "#     log_dir: str = \"runs/experiment\"\n",
        "# ):\n",
        "#     model = model.to(device)\n",
        "#     writer = SummaryWriter(log_dir=log_dir)\n",
        "#     optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\" if maximize_monitor else \"min\",\n",
        "#                                                             factor=0.5, patience=3, verbose=True)\n",
        "#     loss_fn = CombinedLoss(alpha=alpha, beta=beta, weight_gamma=weight_gamma)\n",
        "#     scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "#     best_metric = None\n",
        "#     history = []\n",
        "\n",
        "#     for epoch in range(1, num_epochs + 1):\n",
        "#         train_stats = train_one_epoch(model, train_loader, optimizer, loss_fn, device, scaler if use_amp else None, grad_clip=grad_clip, accum_steps=accum_steps)\n",
        "#         val_stats = eval_one_epoch(model, val_loader, loss_fn, device)\n",
        "#         print(val_stats)\n",
        "\n",
        "#         cur_metric = val_stats.get(monitor, val_stats.get(\"weighted_pearson\", 0.0))\n",
        "#         # scheduler step\n",
        "#         scheduler.step(cur_metric)\n",
        "\n",
        "#         writer.add_scalar('Loss/train', train_stats['train_loss'], epoch)\n",
        "#         writer.add_scalar('Loss/val', val_stats['val_loss'], epoch)\n",
        "#         writer.add_scalar('Corr/train', train_stats['train_mean_abs_corr'], epoch)\n",
        "#         writer.add_scalar('Corr/val', val_stats.get('weighted_pearson', 0.0), epoch)\n",
        "\n",
        "#         improved = (best_metric is None) or (maximize_monitor and cur_metric > best_metric) or (not maximize_monitor and cur_metric < best_metric)\n",
        "#         if improved:\n",
        "#             best_metric = cur_metric\n",
        "#             torch.save({\n",
        "#                 \"epoch\": epoch,\n",
        "#                 \"model_state_dict\": model.state_dict(),\n",
        "#                 \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "#                 \"best_metric\": best_metric,\n",
        "#             }, save_path)\n",
        "#             print(f\"Saved new best model at epoch {epoch}: {best_metric:.6f}\")\n",
        "\n",
        "#         # log\n",
        "#         row = {\"epoch\": epoch}\n",
        "#         row.update(train_stats)\n",
        "#         row.update(val_stats)\n",
        "#         history.append(row)\n",
        "\n",
        "#         print(f\"Epoch {epoch:03d} | train_loss={train_stats['train_loss']:.6f} train_corr={train_stats['train_mean_abs_corr']:.6f} train_corr_by_ch={train_stats['train_mean_corr_by_ch']}\"\n",
        "#               f\"| val_loss={val_stats['val_loss']:.6f} val_weighted_pearson={val_stats.get('weighted_pearson', 0.0):.6f} val_corr_by_ch={val_stats.get('t1', 0.0), val_stats.get('t2', 0.0)}\")\n",
        "\n",
        "#     writer.close()\n",
        "\n",
        "#     return model, history\n",
        "\n",
        "\n",
        "def fit(\n",
        "    model: nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    device: torch.device,\n",
        "    num_epochs: int = 30,\n",
        "    lr: float = 1e-3,\n",
        "    weight_decay: float = 1e-5,\n",
        "    alpha: float = 1.0,\n",
        "    beta: float = 1.0,\n",
        "    weight_gamma: float = 1.0,\n",
        "    grad_clip: float = 1.0,\n",
        "    accum_steps: int = 1,\n",
        "    use_amp: bool = True,\n",
        "    save_path: str = \"best_model.pt\",\n",
        "    monitor: str = \"weighted_pearson\",  # metric from eval_one_epoch to maximize\n",
        "    maximize_monitor: bool = True,\n",
        "    patience: int = 5  # early stopping patience (epochs without improvement)\n",
        "):\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\" if maximize_monitor else \"min\",\n",
        "                                                            factor=0.5, patience=3, verbose=True)\n",
        "    loss_fn = CombinedLoss(alpha=alpha, beta=beta, weight_gamma=weight_gamma)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "    best_metric = None\n",
        "    history = []\n",
        "    epochs_no_improve = 0  # counter for early stopping\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        train_stats = train_one_epoch(\n",
        "            model,\n",
        "            train_loader,\n",
        "            optimizer,\n",
        "            loss_fn,\n",
        "            device,\n",
        "            scaler if use_amp else None,\n",
        "            grad_clip=grad_clip,\n",
        "            accum_steps=accum_steps,\n",
        "        )\n",
        "\n",
        "        val_stats = eval_one_epoch(model, val_loader, loss_fn, device)\n",
        "\n",
        "        cur_metric = val_stats.get(monitor, val_stats.get(\"weighted_pearson\", 0.0))\n",
        "\n",
        "        # scheduler step\n",
        "        try:\n",
        "            scheduler.step(cur_metric)\n",
        "        except Exception:\n",
        "            # some schedulers expect no-arg step; ignore scheduler errors to be robust\n",
        "            try:\n",
        "                scheduler.step()\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # check improvement\n",
        "        improved = (best_metric is None) or (maximize_monitor and cur_metric > best_metric) or (not maximize_monitor and cur_metric < best_metric)\n",
        "\n",
        "        if improved:\n",
        "            best_metric = cur_metric\n",
        "            epochs_no_improve = 0  # reset counter on improvement\n",
        "            torch.save(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"model_state_dict\": model.state_dict(),\n",
        "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                    \"best_metric\": best_metric,\n",
        "                },\n",
        "                save_path,\n",
        "            )\n",
        "            print(f\"Saved new best model at epoch {epoch}: {best_metric:.6f}\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(\n",
        "                f\"No improvement for {epochs_no_improve}/{patience} epochs \"\n",
        "                f\"(cur {monitor}={cur_metric:.6f}, best={best_metric:.6f})\"\n",
        "            )\n",
        "\n",
        "        # log\n",
        "        row = {\"epoch\": epoch}\n",
        "        row.update(train_stats)\n",
        "        row.update(val_stats)\n",
        "        history.append(row)\n",
        "\n",
        "        print(f\"Epoch {epoch:03d} | train_loss={train_stats['train_loss']:.6f} train_corr={train_stats['train_mean_abs_corr']:.6f} train_corr_by_ch={train_stats['train_mean_corr_by_ch']}\"\n",
        "              f\"| val_loss={val_stats['val_loss']:.6f} val_weighted_pearson={val_stats.get('weighted_pearson', 0.0):.6f} val_corr_by_ch={val_stats.get('t1', 0.0), val_stats.get('t2', 0.0)}\")\n",
        "\n",
        "        # Early stop: break fold training and return (so cross_validate proceeds to next fold)\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(\n",
        "                f\"Early stopping triggered (no improvement for {patience} epochs). \"\n",
        "                \"Stopping training for this fold.\"\n",
        "            )\n",
        "            break\n",
        "\n",
        "    # load best checkpoint if exists (so returned model is the best one)\n",
        "    try:\n",
        "        if os.path.exists(save_path):\n",
        "            ckpt = torch.load(save_path, map_location=device)\n",
        "            model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "            print(\n",
        "                f\"Loaded best model from {save_path} \"\n",
        "                f\"(epoch {ckpt.get('epoch', '?')}, metric={ckpt.get('best_metric')})\"\n",
        "            )\n",
        "    except Exception as e:\n",
        "        print(\"Warning: could not load best checkpoint:\", e)\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "vRL5P8YvEqE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "def seed_worker(worker_id):\n",
        "    \"\"\"Инициализация сида для каждого воркера DataLoader\"\"\"\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def cross_validate(\n",
        "    X: np.ndarray,\n",
        "    Y: np.ndarray,\n",
        "    mask: np.ndarray,\n",
        "    n_splits: int = 5,\n",
        "    seed: int = 42,\n",
        "    model_ctor_kwargs: Optional[dict] = None,\n",
        "    fit_kwargs: Optional[dict] = None,\n",
        "    dataloader_kwargs: Optional[dict] = None,\n",
        "    out_dir: str = \"cv_results\",\n",
        "    trial: \"optuna.trial.Trial\" = None,  # optional for pruning\n",
        ") -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Run KFold cross-validation over sequences.\n",
        "\n",
        "    Args:\n",
        "        X, Y, mask : numpy arrays shaped (N_seq, T, F), (N_seq, T, C), (N_seq, T)\n",
        "        n_splits: number of folds\n",
        "        seed: random seed for reproducibility\n",
        "        model_ctor_kwargs: kwargs for GRU constructor:\n",
        "            input_size, hidden_size, output_size, dropout\n",
        "        fit_kwargs: kwargs that will be forwarded to fit(...)\n",
        "            (num_epochs, lr, etc.)\n",
        "        dataloader_kwargs: kwargs forwarded to DataLoader\n",
        "            (batch_size, num_workers, pin_memory)\n",
        "        out_dir: directory to save fold models and logs\n",
        "\n",
        "    Returns:\n",
        "        (fold_results, summary) where fold_results is list of per-fold dicts,\n",
        "        and summary contains mean/std for main metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    if model_ctor_kwargs is None:\n",
        "        model_ctor_kwargs = {\n",
        "            \"input_size\": X.shape[2],\n",
        "            \"hidden_size\": 256,\n",
        "            \"output_size\": Y.shape[2],\n",
        "            \"dropout\": 0.1,\n",
        "        }\n",
        "    if fit_kwargs is None:\n",
        "        fit_kwargs = {\n",
        "            \"num_epochs\": 20,\n",
        "            \"lr\": 1e-3,\n",
        "            \"weight_decay\": 1e-5,\n",
        "            \"alpha\": 1.0,\n",
        "            \"beta\": 3.0,\n",
        "            \"grad_clip\": 1.0,\n",
        "            \"accum_steps\": 1,\n",
        "            \"use_amp\": True,\n",
        "            \"save_path\": None,  # will be set per-fold\n",
        "            \"monitor\": \"weighted_pearson\",\n",
        "            \"maximize_monitor\": True,\n",
        "        }\n",
        "    if dataloader_kwargs is None:\n",
        "        dataloader_kwargs = {\n",
        "            \"batch_size\": 16,\n",
        "            \"num_workers\": 4,\n",
        "            \"pin_memory\": True,\n",
        "        }\n",
        "\n",
        "\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed-16)\n",
        "    n_seq = X.shape[0]\n",
        "    indices = np.arange(n_seq)\n",
        "\n",
        "    fold_results: List[Dict[str, Any]] = []\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Set seeds for reproducibility\n",
        "    # np.random.seed(seed)\n",
        "    # torch.manual_seed(seed)\n",
        "    # if torch.cuda.is_available():\n",
        "    #     torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(indices), start=1):\n",
        "        print(f\"\\n=== Fold {fold}/{n_splits} ===\")\n",
        "        seed_everything(seed+fold)\n",
        "        # Создаём генератор для воспроизводимого перемешивания в DataLoader\n",
        "        generator = torch.Generator()\n",
        "        generator.manual_seed(seed + fold)\n",
        "\n",
        "        X_train, Y_train, mask_train = X[train_idx], Y[train_idx], mask[train_idx]\n",
        "        X_val, Y_val, mask_val = X[val_idx], Y[val_idx], mask[val_idx]\n",
        "\n",
        "        ds_train = TimeSeriesDataset(X_train, Y_train, mask_train,\n",
        "                                     precompute_weights=True)\n",
        "        ds_val = TimeSeriesDataset(X_val, Y_val, mask_val,\n",
        "                                   precompute_weights=True)\n",
        "\n",
        "        train_loader = DataLoader(ds_train, shuffle=True, **{**dataloader_kwargs, \"worker_init_fn\": seed_worker, \"generator\": generator})\n",
        "        # larger batch for eval if memory allows\n",
        "        val_batch_size = dataloader_kwargs.get(\"batch_size\", 16) * 2\n",
        "        val_loader = DataLoader(\n",
        "            ds_val,\n",
        "            shuffle=False,\n",
        "            **{**dataloader_kwargs, \"batch_size\": val_batch_size}\n",
        "        )\n",
        "\n",
        "\n",
        "        model = BaselineGRU(**model_ctor_kwargs)\n",
        "\n",
        "        fold_save = os.path.join(out_dir, f\"best_model_fold{fold}.pt\")\n",
        "        fit_kwargs_local = dict(fit_kwargs)\n",
        "        fit_kwargs_local[\"save_path\"] = fold_save\n",
        "\n",
        "\n",
        "\n",
        "        model, history = fit(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device,\n",
        "            **fit_kwargs_local\n",
        "        )\n",
        "\n",
        "        # Load best checkpoint\n",
        "        if os.path.exists(fold_save):\n",
        "            ckpt = torch.load(fold_save, map_location=device)\n",
        "            model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "            print(f\"Loaded best checkpoint for fold {fold} \"\n",
        "                  f\"(epoch {ckpt.get('epoch', '?')})\")\n",
        "        else:\n",
        "            print(f\"Warning: no checkpoint saved for fold {fold}, \"\n",
        "                  \"using final model\")\n",
        "\n",
        "        # Final validation metrics\n",
        "        loss_fn = CombinedLoss(\n",
        "            alpha=fit_kwargs_local.get(\"alpha\", 1.0),\n",
        "            beta=fit_kwargs_local.get(\"beta\", 1.0),\n",
        "            weight_gamma=fit_kwargs_local.get(\"weight_gamma\", 1.0)\n",
        "        )\n",
        "        val_stats = eval_one_epoch(model, val_loader, loss_fn, device)\n",
        "\n",
        "        # --- Report to Optuna pruner ---\n",
        "        monitor_metric = fit_kwargs_local.get(\"monitor\", \"weighted_pearson\")\n",
        "        fold_metric = float(\n",
        "            val_stats.get(monitor_metric, val_stats.get(\"weighted_pearson\", 0.0))\n",
        "        )\n",
        "        if trial is not None:\n",
        "            trial.report(fold_metric, fold)\n",
        "            if trial.should_prune():\n",
        "                trial.set_user_attr(\"pruned_after_fold\", fold)\n",
        "                raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        fold_info = {\n",
        "            \"fold\": fold,\n",
        "            \"train_size\": len(train_idx),\n",
        "            \"val_size\": len(val_idx),\n",
        "            \"val_stats\": val_stats,\n",
        "            \"history\": history,\n",
        "            \"model_path\": fold_save,\n",
        "        }\n",
        "        fold_results.append(fold_info)\n",
        "\n",
        "    # Aggregate results\n",
        "    pears = []\n",
        "    mses = []\n",
        "    for fr in fold_results:\n",
        "        vs = fr[\"val_stats\"]\n",
        "        pears.append(vs.get(\"weighted_pearson\", 0.0))\n",
        "        mses.append(vs.get(\"global_mse\", 0.0))\n",
        "\n",
        "    pears = np.array(pears)\n",
        "    mses = np.array(mses)\n",
        "\n",
        "    summary = {\n",
        "        \"n_folds\": n_splits,\n",
        "        \"pearson_mean\": float(np.mean(pears)),\n",
        "        \"pearson_std\": float(np.std(pears, ddof=0)),\n",
        "        \"global_mse_mean\": float(np.mean(mses)),\n",
        "        \"global_mse_std\": float(np.std(mses, ddof=0)),\n",
        "    }\n",
        "\n",
        "    print(\"\\n=== CV Summary ===\")\n",
        "    print(f\"Weighted Pearson per-fold: {pears.tolist()}\")\n",
        "    print(f\"Mean ± Std = {summary['pearson_mean']:.6f} ± {summary['pearson_std']:.6f}\")\n",
        "    print(f\"Global MSE per-fold: {mses.tolist()}\")\n",
        "    print(f\"Mean ± Std = {summary['global_mse_mean']:.6f} ± {summary['global_mse_std']:.6f}\")\n",
        "\n",
        "    return fold_results, summary\n",
        "\n",
        "\n",
        "\n",
        "# def cross_validate(\n",
        "#     X: np.ndarray,\n",
        "#     Y: np.ndarray,\n",
        "#     mask: np.ndarray,\n",
        "#     n_splits: int = 5,\n",
        "#     seed: int = 42,\n",
        "#     # models_random_states: List = [],\n",
        "#     model_ctor_kwargs: Optional[dict] = None,\n",
        "#     fit_kwargs: Optional[dict] = None,\n",
        "#     dataloader_kwargs: Optional[dict] = None,\n",
        "#     out_dir: str = \"cv_results\",\n",
        "# ) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:\n",
        "#     \"\"\"\n",
        "#     Run KFold cross-validation over sequences.\n",
        "\n",
        "#     Args:\n",
        "#         X, Y, mask : numpy arrays shaped (N_seq, T, F), (N_seq, T, C), (N_seq, T)\n",
        "#         n_splits: number of folds\n",
        "#         seed: random seed for reproducibility\n",
        "#         model_ctor_kwargs: kwargs for GRU constructor:\n",
        "#             input_size, hidden_size, output_size, dropout\n",
        "#         fit_kwargs: kwargs that will be forwarded to fit(...)\n",
        "#             (num_epochs, lr, etc.)\n",
        "#         dataloader_kwargs: kwargs forwarded to DataLoader\n",
        "#             (batch_size, num_workers, pin_memory)\n",
        "#         out_dir: directory to save fold models and logs\n",
        "\n",
        "#     Returns:\n",
        "#         (fold_results, summary) where fold_results is list of per-fold dicts,\n",
        "#         and summary contains mean/std for main metrics.\n",
        "#     \"\"\"\n",
        "\n",
        "#     os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "#     # if models_random_states == []:\n",
        "#     #     self.seeds = [42] * n_splits\n",
        "#     # elif len(models_random_states) != n_splits:\n",
        "#     #     raise ValueError(\"Длина models_random_states должна совпадать с n_splits\")\n",
        "\n",
        "#     # defaults\n",
        "#     if model_ctor_kwargs is None:\n",
        "#         model_ctor_kwargs = {\n",
        "#             \"input_size\": X.shape[2],\n",
        "#             \"hidden_size\": 256,\n",
        "#             \"output_size\": Y.shape[2],\n",
        "#             \"dropout\": 0.1,\n",
        "#         }\n",
        "#     if fit_kwargs is None:\n",
        "#         fit_kwargs = {\n",
        "#             \"num_epochs\": 20,\n",
        "#             \"lr\": 1e-3,\n",
        "#             \"weight_decay\": 1e-5,\n",
        "#             \"alpha\": 1.0,\n",
        "#             \"beta\": 3.0,\n",
        "#             \"grad_clip\": 1.0,\n",
        "#             \"accum_steps\": 1,\n",
        "#             \"use_amp\": True,\n",
        "#             \"save_path\": None,          # will be set per-fold\n",
        "#             \"monitor\": \"weighted_pearson\",\n",
        "#             \"maximize_monitor\": True,\n",
        "#         }\n",
        "#     if dataloader_kwargs is None:\n",
        "#         dataloader_kwargs = {\n",
        "#             \"batch_size\": 16,\n",
        "#             \"num_workers\": 4,\n",
        "#             \"pin_memory\": True,\n",
        "#         }\n",
        "\n",
        "#     # Prepare KFold\n",
        "#     kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed-16)\n",
        "#     n_seq = X.shape[0]\n",
        "#     indices = np.arange(n_seq)\n",
        "\n",
        "#     fold_results: List[Dict[str, Any]] = []\n",
        "\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#     # For reproducibility: set seeds\n",
        "#     # np.random.seed(seed)\n",
        "#     # torch.manual_seed(seed)\n",
        "#     # if torch.cuda.is_available():\n",
        "#     #     torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "#     for fold, (train_idx, val_idx) in enumerate(kf.split(indices), start=1):\n",
        "#     # for fold, vals in enumerate(zip(kf.split(train_data), models_random_states), start=1):\n",
        "#         print(f\"\\n=== Fold {fold}/{n_splits} ===\")\n",
        "#         # train_idx, val_idx = vals[0][0], vals[0][1]\n",
        "#         # rs = vals[1]\n",
        "#         seed_everything(seed+fold)\n",
        "#         # Создаём генератор для воспроизводимого перемешивания в DataLoader\n",
        "#         generator = torch.Generator()\n",
        "#         generator.manual_seed(seed + fold)\n",
        "#         # prepare datasets/loaders\n",
        "#         X_train, Y_train, mask_train = X[train_idx], Y[train_idx], mask[train_idx]\n",
        "#         X_val, Y_val, mask_val = X[val_idx], Y[val_idx], mask[val_idx]\n",
        "\n",
        "#         ds_train = TimeSeriesDataset(X_train, Y_train, mask_train,\n",
        "#                                      precompute_weights=True)\n",
        "#         ds_val = TimeSeriesDataset(X_val, Y_val, mask_val,\n",
        "#                                    precompute_weights=True)\n",
        "\n",
        "#         train_loader = DataLoader(ds_train, shuffle=True, **{**dataloader_kwargs, \"worker_init_fn\": seed_worker, \"generator\": generator})\n",
        "#         # For eval we can use larger batch size if memory allows\n",
        "#         val_batch_size = dataloader_kwargs.get(\"batch_size\", 16) * 2\n",
        "#         val_loader = DataLoader(\n",
        "#             ds_val,\n",
        "#             shuffle=False,\n",
        "#             **{**dataloader_kwargs, \"batch_size\": val_batch_size}\n",
        "#         )\n",
        "\n",
        "#         # build model fresh for each fold\n",
        "#         model = BaselineGRU(**model_ctor_kwargs)\n",
        "\n",
        "#         # unique save path per fold\n",
        "#         fold_save = os.path.join(out_dir, f\"best_model_fold{fold}.pt\")\n",
        "#         fit_kwargs_local = dict(fit_kwargs)\n",
        "#         fit_kwargs_local[\"save_path\"] = fold_save\n",
        "\n",
        "#         # Train\n",
        "#         model, history = fit(\n",
        "#             model,\n",
        "#             train_loader,\n",
        "#             val_loader,\n",
        "#             device,\n",
        "#             **fit_kwargs_local\n",
        "#         )\n",
        "\n",
        "#         # load best checkpoint (fit saved best to fold_save)\n",
        "#         if os.path.exists(fold_save):\n",
        "#             ckpt = torch.load(fold_save, map_location=device)\n",
        "#             model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "#             print(f\"Loaded best checkpoint for fold {fold} \"\n",
        "#                   f\"(epoch {ckpt.get('epoch', '?')})\")\n",
        "#         else:\n",
        "#             print(f\"Warning: no checkpoint saved for fold {fold}, \"\n",
        "#                   \"using final model\")\n",
        "\n",
        "#         # final evaluation on validation (global metric computation)\n",
        "#         loss_fn = CombinedLoss(\n",
        "#             alpha=fit_kwargs_local.get(\"alpha\", 1.0),\n",
        "#             beta=fit_kwargs_local.get(\"beta\", 1.0),\n",
        "#             weight_gamma=fit_kwargs_local.get(\"weight_gamma\", 1.0)\n",
        "#         )\n",
        "#         val_stats = eval_one_epoch(model, val_loader, loss_fn, device)\n",
        "#         # eval_one_epoch returns dict with keys including\n",
        "#         # \"weighted_pearson\" and \"global_mse\" (see previously)\n",
        "\n",
        "#         # keep fold info\n",
        "#         fold_info = {\n",
        "#             \"fold\": fold,\n",
        "#             \"train_size\": len(train_idx),\n",
        "#             \"val_size\": len(val_idx),\n",
        "#             \"val_stats\": val_stats,\n",
        "#             \"history\": history,          # may be large; drop if not needed\n",
        "#             \"model_path\": fold_save,\n",
        "#         }\n",
        "#         fold_results.append(fold_info)\n",
        "\n",
        "#     # Aggregate results\n",
        "#     # Extract weighted_pearson and global_mse per fold\n",
        "#     pears = []\n",
        "#     mses = []\n",
        "#     for fr in fold_results:\n",
        "#         vs = fr[\"val_stats\"]\n",
        "#         pears.append(vs.get(\"weighted_pearson\", 0.0))\n",
        "#         mses.append(vs.get(\"global_mse\", 0.0))\n",
        "\n",
        "#     pears = np.array(pears)\n",
        "#     mses = np.array(mses)\n",
        "\n",
        "#     summary = {\n",
        "#         \"n_folds\": n_splits,\n",
        "#         \"pearson_mean\": float(np.mean(pears)),\n",
        "#         \"pearson_std\": float(np.std(pears, ddof=0)),\n",
        "#         \"global_mse_mean\": float(np.mean(mses)),\n",
        "#         \"global_mse_std\": float(np.std(mses, ddof=0)),\n",
        "#     }\n",
        "\n",
        "#     print(\"\\n=== CV Summary ===\")\n",
        "#     print(f\"Weighted Pearson per-fold: {pears.tolist()}\")\n",
        "#     print(f\"Mean ± Std = {summary['pearson_mean']:.6f} ± \"\n",
        "#           f\"{summary['pearson_std']:.6f}\")\n",
        "#     print(f\"Global MSE per-fold: {mses.tolist()}\")\n",
        "#     print(f\"Mean ± Std = {summary['global_mse_mean']:.6f} ± \"\n",
        "#           f\"{summary['global_mse_std']:.6f}\")\n",
        "\n",
        "#     return fold_results, summary"
      ],
      "metadata": {
        "id": "c9x6CodGEu9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble_inference(\n",
        "    model_paths: List[str],\n",
        "    dataloader: DataLoader,\n",
        "    device: torch.device,\n",
        "    model_ctor,\n",
        "    model_kwargs: dict,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Делает инференс ансамбля моделей с усреднением предсказаний.\n",
        "\n",
        "    Args:\n",
        "        model_paths: список путей к чекпоинтам моделей\n",
        "        dataloader: DataLoader для инференса\n",
        "        device: torch.device\n",
        "        model_ctor: конструктор модели (например ThreeLayerGRU)\n",
        "        model_kwargs: аргументы конструктора модели\n",
        "\n",
        "    Returns:\n",
        "        preds_mean: numpy array (N_seq, T, C)\n",
        "    \"\"\"\n",
        "\n",
        "    all_model_preds = []\n",
        "\n",
        "    for path in model_paths:\n",
        "        print(f\"Loading model: {path}\")\n",
        "\n",
        "        # создать модель\n",
        "        model = model_ctor(**model_kwargs)\n",
        "        ckpt = torch.load(path, map_location=device)\n",
        "        model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        preds_list = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader:\n",
        "                X = batch[0].to(device, non_blocking=True)\n",
        "\n",
        "                preds, _ = model(X)                     # (B, T, C)\n",
        "                preds_list.append(preds.cpu().numpy())\n",
        "\n",
        "        preds_model = np.concatenate(preds_list, axis=0)   # (N_seq, T, C)\n",
        "        all_model_preds.append(preds_model)\n",
        "\n",
        "    # stack: (n_models, N_seq, T, C)\n",
        "    all_model_preds = np.stack(all_model_preds, axis=0)\n",
        "\n",
        "    # усреднение по моделям\n",
        "    preds_mean = np.mean(all_model_preds, axis=0)\n",
        "\n",
        "    return preds_mean\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#     model_paths = [\n",
        "#         \"cv_out/best_model_fold1.pt\",\n",
        "#         \"cv_out/best_model_fold2.pt\",\n",
        "#         \"cv_out/best_model_fold3.pt\",\n",
        "#         \"cv_out/best_model_fold4.pt\",\n",
        "#         \"cv_out/best_model_fold5.pt\",\n",
        "#     ]\n",
        "\n",
        "#     model_kwargs = {\n",
        "#         \"input_size\": 32,\n",
        "#         \"hidden_size\": 256,\n",
        "#         \"output_size\": 2,\n",
        "#         \"dropout\": 0.1,\n",
        "#     }\n",
        "\n",
        "#     # dataloader для теста\n",
        "#     test_loader = DataLoader(\n",
        "#         test_dataset,\n",
        "#         batch_size=32,\n",
        "#         shuffle=False,\n",
        "#         num_workers=4,\n",
        "#         pin_memory=True,\n",
        "#     )\n",
        "\n",
        "#     preds = ensemble_inference(\n",
        "#         model_paths=model_paths,\n",
        "#         dataloader=test_loader,\n",
        "#         device=device,\n",
        "#         model_ctor=ThreeLayerGRU,\n",
        "#         model_kwargs=model_kwargs,\n",
        "#     )\n",
        "\n",
        "#     print(preds.shape)"
      ],
      "metadata": {
        "id": "01Vgh0h9EyHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import mlflow\n",
        "import mlflow.exceptions\n",
        "import mlflow.tracking\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict\n",
        "\n",
        "# Импортируй свою cross_validate из того модуля, где ты её держишь\n",
        "# from your_module import cross_validate\n",
        "\n",
        "# --------------------------\n",
        "# Helper: сохранять прогресс Optuna в CSV/JSON\n",
        "# --------------------------\n",
        "def save_study_progress(study: optuna.study.Study, trial: optuna.trial.FrozenTrial, out_dir: str):\n",
        "    \"\"\"\n",
        "    Optuna callback: сохраняет таблицу trials в CSV и небольшой summary в JSON.\n",
        "    Вызывается после завершения каждого trial.\n",
        "    \"\"\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    df = study.trials_dataframe()\n",
        "    csv_path = os.path.join(out_dir, \"optuna_trials.csv\")\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "    # Save a compact JSON with per-trial summary useful for quick look\n",
        "    summary = []\n",
        "    for t in study.trials:\n",
        "        summary.append({\n",
        "            \"number\": t.number,\n",
        "            \"state\": str(t.state),\n",
        "            \"value\": None if t.value is None else float(t.value),\n",
        "            \"params\": t.params,\n",
        "            \"datetime_start\": str(t.datetime_start),\n",
        "            \"datetime_complete\": str(t.datetime_complete),\n",
        "            \"user_attrs\": t.user_attrs,\n",
        "            \"system_attrs\": t.system_attrs,\n",
        "        })\n",
        "    json_path = os.path.join(out_dir, \"optuna_summary.json\")\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump(summary, f, indent=2, default=str)\n",
        "\n",
        "    # Optionally, pickle the study object for later analysis\n",
        "    pkl_path = os.path.join(out_dir, \"optuna_study.pkl\")\n",
        "    try:\n",
        "        with open(pkl_path, \"wb\") as pf:\n",
        "            pickle.dump(study, pf)\n",
        "    except Exception as e:\n",
        "        # pickling Study may fail in some setups (e.g., if DB storage used) — ignore quietly\n",
        "        print(\"Warning: could not pickle study:\", e)\n",
        "\n",
        "# --------------------------\n",
        "# Main: make objective with MLflow logging\n",
        "# --------------------------\n",
        "def make_objective_with_mlflow(\n",
        "    X: np.ndarray,\n",
        "    Y: np.ndarray,\n",
        "    mask: np.ndarray,\n",
        "    cross_validate_fn,\n",
        "    n_splits: int = 5,\n",
        "    seed: int = 42,\n",
        "    base_model_ctor_kwargs: Dict[str, Any] = None,\n",
        "    base_fit_kwargs: Dict[str, Any] = None,\n",
        "    base_dataloader_kwargs: Dict[str, Any] = None,\n",
        "    mlflow_experiment: str = \"optuna_cv\",\n",
        "    log_models_as_artifacts: bool = False,\n",
        "    optuna_progress_dir: str = \"optuna_progress\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Возвращает objective(trial) для optuna, который логирует в MLflow и сохраняет прогресс trials в CSV/JSON.\n",
        "    - cross_validate_fn: твоя функция cross_validate(X,Y,mask, ...)\n",
        "    - log_models_as_artifacts: если True — будут загружены в MLflow все файлы из trial_dir (может быть много, осторожно).\n",
        "    \"\"\"\n",
        "    if base_model_ctor_kwargs is None:\n",
        "        base_model_ctor_kwargs = {\"input_size\": X.shape[2], \"hidden_size\": 256, \"output_size\": Y.shape[2], \"dropout\": 0.1}\n",
        "    if base_fit_kwargs is None:\n",
        "        base_fit_kwargs = {\n",
        "            \"num_epochs\": 50,\n",
        "            \"lr\": 1e-3,\n",
        "            \"weight_decay\": 1e-5,\n",
        "            \"alpha\": 1.0,\n",
        "            \"beta\": 3.0,\n",
        "            \"grad_clip\": 1.0,\n",
        "            \"accum_steps\": 1,\n",
        "            \"use_amp\": True,\n",
        "            \"save_path\": None,\n",
        "            \"monitor\": \"weighted_pearson\",\n",
        "            \"maximize_monitor\": True,\n",
        "        }\n",
        "    if base_dataloader_kwargs is None:\n",
        "        base_dataloader_kwargs = {\"batch_size\": 16, \"num_workers\": 4, \"pin_memory\": True}\n",
        "\n",
        "    # ensure mlflow experiment exists\n",
        "    mlflow.set_experiment(mlflow_experiment)\n",
        "\n",
        "# как считается score на cv?\n",
        "    def objective(trial: optuna.trial.Trial):\n",
        "        # ----------------------\n",
        "        # Optuna search space (пример — настраивай под себя)\n",
        "        # ----------------------\n",
        "        hidden_size = 2**trial.suggest_int(\"hidden_size\", 4, 9)\n",
        "        dropout = trial.suggest_float(\"dropout\", 0.0, 0.5, step=0.05)\n",
        "        lr = trial.suggest_loguniform(\"lr\", 1e-5, 5e-3)\n",
        "        weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-15, 1e-2)\n",
        "        # batch_size = trial.suggest_categorical(\"batch_size\", [256])\n",
        "        batch_size = 256\n",
        "        alpha = trial.suggest_float(\"alpha\", 0.01, 1.0)\n",
        "        # beta = trial.suggest_float(\"beta\", 0.5, 6.0)\n",
        "        beta = 1-alpha\n",
        "        weight_gamma = trial.suggest_float(\"weight_gamma\", 0.4, 1.0, step=0.05)\n",
        "        max_weight = 50\n",
        "\n",
        "        num_layers = trial.suggest_int(\"num_layers\", 1, 5)\n",
        "        in_layernorm = trial.suggest_categorical(\"in_layernorm\",[True,False])\n",
        "        out_layernorm = trial.suggest_categorical(\"out_layernorm\",[True,False])\n",
        "\n",
        "        # ----------------------\n",
        "        # Prepare kwargs for cross_validate\n",
        "        # ----------------------\n",
        "        model_ctor_kwargs = dict(base_model_ctor_kwargs)\n",
        "        model_ctor_kwargs.update({\n",
        "            \"input_size\": X.shape[2],\n",
        "            \"hidden_size\": hidden_size,\n",
        "            \"output_size\": Y.shape[2],\n",
        "            \"dropout\": dropout,\n",
        "            \"num_layers\": num_layers,\n",
        "            \"in_layernorm\": in_layernorm,\n",
        "            \"out_layernorm\": out_layernorm\n",
        "        })\n",
        "\n",
        "        fit_kwargs = dict(base_fit_kwargs)\n",
        "        fit_kwargs.update({\n",
        "            \"lr\": lr,\n",
        "            \"weight_decay\": weight_decay,\n",
        "            \"alpha\": alpha,\n",
        "            \"weight_gamma\": weight_gamma#,\n",
        "            # \"max_weight\": max_weight\n",
        "            # ensure save_path is templated; cross_validate will set per-fold paths\n",
        "            # we'll create per-trial folder below\n",
        "        })\n",
        "\n",
        "        dataloader_kwargs = dict(base_dataloader_kwargs)\n",
        "        dataloader_kwargs.update({\"batch_size\": batch_size})\n",
        "        print(dataloader_kwargs)\n",
        "\n",
        "        # ----------------------\n",
        "        # Create trial-specific directory (contains per-fold models saved by cross_validate)\n",
        "        # ----------------------\n",
        "        trial_dir = os.path.join(\"optuna_trials\", f\"trial_{trial.number}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
        "        os.makedirs(trial_dir, exist_ok=True)\n",
        "        fit_kwargs_local = dict(fit_kwargs)\n",
        "        fit_kwargs_local[\"save_path\"] = os.path.join(trial_dir, \"best_model_fold{fold}.pt\")\n",
        "\n",
        "        # ----------------------\n",
        "        # Start MLflow run (one run per trial)\n",
        "        # ----------------------\n",
        "        # Using nested runs makes it easy to view all trials under the experiment\n",
        "        with mlflow.start_run(run_name=f\"optuna_trial_{trial.number}\", nested=True):\n",
        "            # log trial params (some from trial.suggest_*)\n",
        "            mlflow.log_param(\"hidden_size\", hidden_size)\n",
        "            mlflow.log_param(\"num_layers\", num_layers)\n",
        "            mlflow.log_param(\"dropout\", dropout)\n",
        "            mlflow.log_param(\"in_layernorm\", in_layernorm)\n",
        "            mlflow.log_param(\"out_layernorm\", out_layernorm)\n",
        "            mlflow.log_param(\"lr\", lr)\n",
        "            mlflow.log_param(\"weight_decay\", weight_decay)\n",
        "            mlflow.log_param(\"batch_size\", batch_size)\n",
        "            mlflow.log_param(\"alpha\", alpha)\n",
        "            mlflow.log_param(\"weight_gamma\", weight_gamma)\n",
        "            mlflow.log_param(\"n_splits\", n_splits)\n",
        "            mlflow.log_param(\"seed\", seed)\n",
        "\n",
        "            # Optionally store the full dict of trial.params\n",
        "            mlflow.set_tag(\"optuna_trial_number\", str(trial.number))\n",
        "\n",
        "            # ----------------------\n",
        "            # Run cross-validation (costly)\n",
        "            # ----------------------\n",
        "            # try:\n",
        "            #     fold_results, summary = cross_validate_fn(\n",
        "            #         X, Y, mask,\n",
        "            #         n_splits=n_splits,\n",
        "            #         seed=seed,\n",
        "            #         model_ctor_kwargs=model_ctor_kwargs,\n",
        "            #         fit_kwargs=fit_kwargs_local,\n",
        "            #         dataloader_kwargs=dataloader_kwargs,\n",
        "            #         out_dir=trial_dir,\n",
        "            #     )\n",
        "            try:\n",
        "                fold_results, summary = cross_validate_fn(\n",
        "                    X, Y, mask,\n",
        "                    n_splits=n_splits,\n",
        "                    seed=seed,\n",
        "                    model_ctor_kwargs=model_ctor_kwargs,\n",
        "                    fit_kwargs=fit_kwargs_local,\n",
        "                    dataloader_kwargs=dataloader_kwargs,\n",
        "                    out_dir=trial_dir,\n",
        "                    trial=trial,  # <-- передаём trial\n",
        "                )\n",
        "            except optuna.exceptions.TrialPruned:\n",
        "                # important: re-raise so Optuna can mark trial as pruned\n",
        "                print(f\"Trial {trial.number} pruned by pruner during cross-validation.\")\n",
        "                raise\n",
        "            except Exception as e:\n",
        "                # Log exception into MLflow and as trial attr, then re-raise (trial will be failed)\n",
        "                mlflow.log_param(\"failed\", True)\n",
        "                mlflow.set_tag(\"error\", str(e))\n",
        "                trial.set_user_attr(\"error\", str(e))\n",
        "                raise\n",
        "\n",
        "            # ----------------------\n",
        "            # Log summary metrics & artifacts to MLflow\n",
        "            # ----------------------\n",
        "            # summary is a dict returned by cross_validate (pearson_mean, etc.)\n",
        "            if summary is not None:\n",
        "                for k, v in summary.items():\n",
        "                    try:\n",
        "                        mlflow.log_metric(k, float(v))\n",
        "                    except Exception:\n",
        "                        # ignore non-float entries\n",
        "                        mlflow.log_param(f\"metric_{k}\", str(v))\n",
        "\n",
        "            # Save fold_results as JSON artifact\n",
        "            try:\n",
        "                fr_json = os.path.join(trial_dir, \"fold_results.json\")\n",
        "                with open(fr_json, \"w\") as fw:\n",
        "                    json.dump(fold_results, fw, default=str, indent=2)\n",
        "                mlflow.log_artifact(fr_json, artifact_path=\"fold_results\")\n",
        "            except Exception as e:\n",
        "                print(\"Warning: cannot save fold_results.json:\", e)\n",
        "\n",
        "            # Optionally: log all files saved in trial_dir (models, logs)\n",
        "            if log_models_as_artifacts:\n",
        "                try:\n",
        "                    mlflow.log_artifacts(trial_dir, artifact_path=\"trial_files\")\n",
        "                except Exception as e:\n",
        "                    print(\"Warning: mlflow.log_artifacts failed:\", e)\n",
        "\n",
        "            # Store summary and fold_results in trial.user_attrs for offline analysis\n",
        "            print(fold_results)\n",
        "            trial.set_user_attr(\"summary\", summary)\n",
        "            trial.set_user_attr(\"fold_results\", fold_results)\n",
        "\n",
        "            # return the metric to optuna (the metric we want to maximize)\n",
        "            pearson_mean = summary.get(\"pearson_mean\", None)\n",
        "            if pearson_mean is None:\n",
        "                # if there is no valid metric, mark as pruned/failed; here we'll prune\n",
        "                raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "            return float(pearson_mean)\n",
        "\n",
        "    return objective"
      ],
      "metadata": {
        "id": "qeEQ8wuKE0eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_optuna_search(\n",
        "    X, Y, mask,\n",
        "    cross_validate_fn,\n",
        "    n_trials: int = 30,\n",
        "    n_splits: int = 10,\n",
        "    seed: int = 42,\n",
        "    study_name: str = \"optuna_mlflow_cv\",\n",
        "    storage_url: str = \"sqlite:///optuna_study.db\",\n",
        "    base_model_ctor_kwargs: Dict[str, Any] = None,\n",
        "    base_fit_kwargs: Dict[str, Any] = None,\n",
        "    base_dataloader_kwargs: Dict[str, Any] = None,\n",
        "    mlflow_experiment: str = \"optuna_cv\",\n",
        "    log_models_as_artifacts: bool = False,\n",
        "    optuna_progress_dir: str = \"optuna_progress\",\n",
        "    n_jobs: int = 1\n",
        "):\n",
        "    # create study\n",
        "    sampler = optuna.samplers.TPESampler(seed=seed)\n",
        "    pruner = optuna.pruners.MedianPruner(n_warmup_steps=1) # можно настраивать\n",
        "    study = optuna.create_study(study_name=study_name, storage=storage_url,\n",
        "                                sampler=sampler, pruner=pruner, direction=\"maximize\", load_if_exists=True)\n",
        "\n",
        "\n",
        "    # make objective\n",
        "    objective = make_objective_with_mlflow(\n",
        "        X, Y, mask,\n",
        "        cross_validate_fn=cross_validate_fn,\n",
        "        n_splits=n_splits,\n",
        "        seed=seed,\n",
        "        base_model_ctor_kwargs=base_model_ctor_kwargs,\n",
        "        base_fit_kwargs=base_fit_kwargs,\n",
        "        base_dataloader_kwargs=base_dataloader_kwargs,\n",
        "        mlflow_experiment=mlflow_experiment,\n",
        "        log_models_as_artifacts=log_models_as_artifacts,\n",
        "        optuna_progress_dir=optuna_progress_dir\n",
        "    )\n",
        "\n",
        "    # prepare progress directory and callback\n",
        "    progress_dir = \"optuna_progress\"\n",
        "    os.makedirs(progress_dir, exist_ok=True)\n",
        "    cb = lambda study, trial: save_study_progress(study, trial, out_dir=progress_dir)\n",
        "\n",
        "    # Optimize. If you want parallel runs, launch multiple processes each calling this same function.\n",
        "    study.optimize(objective, n_trials=n_trials, callbacks=[cb])\n",
        "\n",
        "    # once finished, save final trials CSV\n",
        "    save_study_progress(study, None, out_dir=progress_dir)\n",
        "\n",
        "    print(\"Optimization finished.\")\n",
        "    print(\"Best trial:\")\n",
        "    print(\" Value:\", study.best_value)\n",
        "    print(\" Params:\")\n",
        "    for k, v in study.best_params.items():\n",
        "        print(f\" {k}: {v}\")\n",
        "    return study"
      ],
      "metadata": {
        "id": "YKugRRiRE3yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение бейзлайна"
      ],
      "metadata": {
        "id": "RDUBgKvME5ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineGRU(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int,\n",
        "        hidden_size: int,\n",
        "        output_size: int,\n",
        "        num_layers: int,\n",
        "        dropout: float = 0.0,\n",
        "        in_layernorm: bool = True,\n",
        "        out_layernorm: bool = True\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.in_layernorm = in_layernorm\n",
        "        self.out_layernorm = out_layernorm\n",
        "\n",
        "        # входная проекция (опционально) + LayerNorm\n",
        "        if self.in_layernorm:\n",
        "            self.input_proj = nn.Linear(self.input_size, self.hidden_size)\n",
        "            self.input_ln = nn.LayerNorm(self.hidden_size)\n",
        "\n",
        "        gru_in_size = self.hidden_size if self.in_layernorm else self.input_size\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=gru_in_size,\n",
        "            hidden_size=self.hidden_size,\n",
        "            num_layers=self.num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=self.dropout if self.num_layers > 1 else 0.0,\n",
        "            bidirectional=False,\n",
        "        )\n",
        "\n",
        "        if self.out_layernorm:\n",
        "            self.out_ln = nn.LayerNorm(self.hidden_size)\n",
        "\n",
        "        self.head = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "        # def _init_weights(self):\n",
        "        #     for name, param in self.named_parameters():\n",
        "        #         if 'weight' in name:\n",
        "        #             nn.init.kaiming_normal_(param)\n",
        "        #         elif 'bias' in name:\n",
        "        #             nn.init.zeros_(param)\n",
        "        nn.init.xavier_uniform_(self.head.weight)\n",
        "        if self.head.bias is not None:\n",
        "            nn.init.zeros_(self.head.bias)\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor, hx: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        x: (B, T, F)\n",
        "        returns:\n",
        "        out: (B, T, C)\n",
        "        h_n: (num_layers, B, H)\n",
        "        \"\"\"\n",
        "        if self.in_layernorm:\n",
        "            x = self.input_proj(x)\n",
        "            x = self.input_ln(x)\n",
        "        out, h_n = self.gru(x, hx)  # out: (B, T, H); hx-начальное скрытое состояние\n",
        "        if self.out_layernorm:\n",
        "            out = self.out_ln(out)\n",
        "        preds = self.head(out)  # (B, T, C)\n",
        "        return preds, h_n"
      ],
      "metadata": {
        "id": "QIg_fIeAE7bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_data['seq_ix'] += 11000\n",
        "tot_data = pd.concat([train_data, eval_data]).reset_index(drop=True)\n",
        "tot_data = tot_data.sample(len(tot_data))"
      ],
      "metadata": {
        "id": "wIJCUFhNE924"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tot, Y_tot, mask_tot = df_to_numpy_arrays(tot_data.sample(len(tot_data)))"
      ],
      "metadata": {
        "id": "F0zstwEIFBlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_params={\n",
        "    \"input_size\": X_tot.shape[2],\n",
        "    \"hidden_size\": 128,\n",
        "    \"output_size\": 2,\n",
        "    \"num_layers\": 3,\n",
        "    \"dropout\": 0.05,\n",
        "    \"in_layernorm\": True,\n",
        "    \"out_layernorm\": True\n",
        "}\n",
        "\n",
        "dataloader_params={\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"num_workers\": 4,\n",
        "    \"pin_memory\": True,\n",
        "    \"prefetch_factor\": 2\n",
        "}\n",
        "\n",
        "fit_params={\n",
        "    \"num_epochs\": 25,\n",
        "    \"lr\": 3e-4,\n",
        "    \"weight_decay\": 1e-5,\n",
        "    \"alpha\": 1.0,\n",
        "    \"beta\": 0.5,\n",
        "    \"weight_gamma\": 1.0,\n",
        "    \"grad_clip\": 2.0,\n",
        "    \"accum_steps\": 1,\n",
        "    \"use_amp\": False,\n",
        "    \"monitor\": \"weighted_pearson\",\n",
        "    \"maximize_monitor\": True,\n",
        "    \"log_dir\": \"./experiments/first_trial\"\n",
        "}\n",
        "\n",
        "fold_results, summary = cross_validate(\n",
        "    X=X_tot,\n",
        "    Y=Y_tot,\n",
        "    mask=mask_tot,\n",
        "    n_splits=5,\n",
        "    seed=42,\n",
        "    model_ctor_kwargs=model_params,\n",
        "    fit_kwargs=fit_params,\n",
        "    dataloader_kwargs=dataloader_params,\n",
        "    out_dir=\"cv_results\"\n",
        ")"
      ],
      "metadata": {
        "id": "EXZrwd-SFDlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_params={\n",
        "#     \"input_size\": X_tot.shape[2],\n",
        "#     \"hidden_size\": 128,\n",
        "#     \"output_size\": 2,\n",
        "#     \"num_layers\": 3,\n",
        "#     \"dropout\": 0.05,\n",
        "#     \"in_layernorm\": True,\n",
        "#     \"out_layernorm\": True\n",
        "# }\n",
        "\n",
        "dataloader_params={\n",
        "    \"num_workers\": 4,\n",
        "    \"pin_memory\": True,\n",
        "    \"prefetch_factor\": 2\n",
        "}\n",
        "\n",
        "fit_params={\n",
        "    \"num_epochs\": 25,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"accum_steps\": 1,\n",
        "    \"use_amp\": False,\n",
        "    \"monitor\": \"weighted_pearson\",\n",
        "    \"maximize_monitor\": True,\n",
        "    # \"log_dir\": \"./experiments/first_trial\",\n",
        "    \"patience\": 5\n",
        "}\n",
        "\n",
        "study = run_optuna_search(\n",
        "    X_tot, Y_tot, mask_tot,\n",
        "    cross_validate_fn=cross_validate,\n",
        "    n_trials=200,\n",
        "    n_splits=3,\n",
        "    seed=42,\n",
        "    study_name=\"my_optuna_study\",\n",
        "    storage_url=\"sqlite:///optuna_study.db\",\n",
        "    base_fit_kwargs=fit_params,\n",
        "    base_dataloader_kwargs=dataloader_params,\n",
        "    mlflow_experiment=\"my_mlflow_experiment\",\n",
        "    n_jobs=1,\n",
        "    log_models_as_artifacts=False,  # True may upload large artifacts\n",
        ")"
      ],
      "metadata": {
        "id": "OClZbBZ8FHNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Экспорт результатов"
      ],
      "metadata": {
        "id": "n54_8MasFLwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "def export_gru_to_onnx(\n",
        "    pytorch_model: nn.Module,\n",
        "    input_size: int,\n",
        "    hidden_size: int,\n",
        "    num_layers: int,\n",
        "    dropout: float,\n",
        "    in_layernorm: bool,\n",
        "    out_layernorm: bool,\n",
        "    onnx_path: str,\n",
        "    opset_version: int = 12,\n",
        "    verbose: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Exports a PyTorch recurrent model (GRU-based) to ONNX.\n",
        "    Forward must return (preds, h_n) where preds shape (B, T, C) and h_n shape (num_layers, B, H).\n",
        "    We export for B=1, T=1 and set dynamic axes on batch/time.\n",
        "    \"\"\"\n",
        "    pytorch_model.eval()\n",
        "    x_dummy = torch.randn(1, 1, input_size, dtype=torch.float32)  # (B=1, T=1, F)\n",
        "    h0_dummy = torch.zeros(num_layers, 1, hidden_size, dtype=torch.float32)  # (num_layers, B=1, H)\n",
        "\n",
        "    input_names = [\"x\", \"h0\"]\n",
        "    output_names = [\"preds\", \"h_n\"]\n",
        "\n",
        "    dynamic_axes = {\n",
        "        \"x\": {0: \"batch\", 1: \"seq\"},\n",
        "        \"h0\": {1: \"batch\"},\n",
        "        \"preds\": {0: \"batch\", 1: \"seq\"},\n",
        "        \"h_n\": {1: \"batch\"},\n",
        "    }\n",
        "\n",
        "    torch.onnx.export(\n",
        "        pytorch_model,\n",
        "        (x_dummy, h0_dummy),\n",
        "        onnx_path,\n",
        "        input_names=input_names,\n",
        "        output_names=output_names,\n",
        "        dynamic_axes=dynamic_axes,\n",
        "        opset_version=opset_version,\n",
        "        do_constant_folding=True,\n",
        "        verbose=verbose,\n",
        "    )\n",
        "    print(f\"Exported ONNX model -> {onnx_path}\")\n",
        "\n",
        "\n",
        "def export_folds_to_onnx(\n",
        "    checkpoint_paths,\n",
        "    onnx_out_dir,\n",
        "    input_size,\n",
        "    hidden_size,\n",
        "    output_size,\n",
        "    num_layers,\n",
        "    dropout,\n",
        "    in_layernorm,\n",
        "    out_layernorm\n",
        "):\n",
        "    os.makedirs(onnx_out_dir, exist_ok=True)\n",
        "    for i, ckpt_path in enumerate(checkpoint_paths, start=1):\n",
        "        model = BaselineGRU(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            output_size=output_size,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            in_layernorm=in_layernorm,\n",
        "            out_layernorm=out_layernorm\n",
        "        )\n",
        "        ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "        model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "        model.eval()\n",
        "        onnx_path = Path(onnx_out_dir) / f\"fold{i}.onnx\"\n",
        "        export_gru_to_onnx(\n",
        "            model,\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            in_layernorm=in_layernorm,\n",
        "            out_layernorm=out_layernorm,\n",
        "            onnx_path=str(onnx_path),\n",
        "        )"
      ],
      "metadata": {
        "id": "LR9LhN0eFJUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_folds_to_onnx(\n",
        "    checkpoint_paths=['/home/jovyan/optuna_trials/trial_95_20260301_035026/models/best_model_fold1.pt', '/home/jovyan/optuna_trials/trial_95_20260301_035026/models/best_model_fold2.pt'],\n",
        "    onnx_out_dir='./onxx_models',\n",
        "    input_size=X_tot.shape[2],\n",
        "    hidden_size=256,\n",
        "    num_layers=4,\n",
        "    output_size=2,\n",
        "    dropout=0,\n",
        "    in_layernorm=False,\n",
        "    out_layernorm=True\n",
        ")"
      ],
      "metadata": {
        "id": "qToYNFigFPWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,'./competition_package')\n",
        "from utils import DataPoint, ScorerStepByStep"
      ],
      "metadata": {
        "id": "KzYMy2wxFRkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "class PredictionModelONNX:\n",
        "    def __init__(\n",
        "        self,\n",
        "        onnx_path: str,\n",
        "        feat_center: Optional[np.ndarray] = None,\n",
        "        feat_scale: Optional[np.ndarray] = None,\n",
        "    ):\n",
        "        self.sess = ort.InferenceSession(onnx_path, providers=[\"CPUExecutionProvider\"])\n",
        "        ins = self.sess.get_inputs()\n",
        "        outs = self.sess.get_outputs()\n",
        "        self.input_name_x = ins[0].name\n",
        "        self.input_name_h0 = ins[1].name if len(ins) > 1 else None\n",
        "        self.output_name_preds = outs[0].name\n",
        "        self.output_name_hn = outs[1].name if len(outs) > 1 else None\n",
        "\n",
        "        self.feat_center = feat_center.astype(np.float32) if feat_center is not None else None\n",
        "        self.feat_scale = feat_scale.astype(np.float32) if feat_scale is not None else None\n",
        "\n",
        "        # per-sequence hidden states store: seq_ix -> h_n (num_layers, 1, hidden_size)\n",
        "        self.hidden_states: Dict[int, np.ndarray] = {}\n",
        "\n",
        "    def reset_sequence(self, seq_ix: int):\n",
        "        if seq_ix in self.hidden_states:\n",
        "            del self.hidden_states[seq_ix]\n",
        "\n",
        "    def predict(self, data_point: DataPoint) -> Optional[np.ndarray]:\n",
        "        if not data_point.need_prediction:\n",
        "            # reset sequence on first step if you want; leave to caller if needed\n",
        "            return None\n",
        "\n",
        "        seq = data_point.seq_ix\n",
        "        step = data_point.step_in_seq\n",
        "        x_raw = np.asarray(data_point.state, dtype=np.float32)  # (F,)\n",
        "\n",
        "        # reset hidden on sequence start (support step starting at 0 or 1)\n",
        "        if seq not in self.hidden_states or step in (0, 1):\n",
        "            # infer expected shapes from session input if available\n",
        "            h0_inp = None\n",
        "            for inp in self.sess.get_inputs():\n",
        "                if inp.name == self.input_name_h0:\n",
        "                    h0_inp = inp\n",
        "                    break\n",
        "            if h0_inp is not None:\n",
        "                proto = h0_inp.shape  # may contain None/strings\n",
        "                # attempt to read numeric entries, fallback if missing\n",
        "                try:\n",
        "                    num_layers = int(proto[0]) if proto[0] not in (None, \"batch\", \"N\", \"\") else 3\n",
        "                    hidden_size = int(proto[2]) if proto[2] not in (None, \"batch\", \"H\", \"\") else 256\n",
        "                except Exception:\n",
        "                    num_layers, hidden_size = 3, 256\n",
        "            else:\n",
        "                num_layers, hidden_size = 3, 256\n",
        "\n",
        "            h0 = np.zeros((num_layers, 1, hidden_size), dtype=np.float32)\n",
        "            self.hidden_states[seq] = h0\n",
        "        else:\n",
        "            h0 = self.hidden_states[seq]\n",
        "\n",
        "        # preprocess features\n",
        "        if self.feat_center is not None and self.feat_scale is not None:\n",
        "            x_proc = (x_raw - self.feat_center) / self.feat_scale\n",
        "        else:\n",
        "            x_proc = x_raw\n",
        "\n",
        "        x_in = x_proc.reshape(1, 1, -1).astype(np.float32)  # (1,1,F)\n",
        "        h0_in = h0.astype(np.float32)\n",
        "\n",
        "        input_feed = {self.input_name_x: x_in}\n",
        "        if self.input_name_h0 is not None:\n",
        "            input_feed[self.input_name_h0] = h0_in\n",
        "\n",
        "        outputs = self.sess.run([self.output_name_preds, self.output_name_hn], input_feed)\n",
        "        preds_np = outputs[0]  # (1,1,C)\n",
        "        h_n_np = outputs[1]  # (num_layers,1,H)\n",
        "\n",
        "        self.hidden_states[seq] = h_n_np\n",
        "        return preds_np.reshape(-1)  # (C,)\n",
        "\n",
        "\n",
        "class EnsemblePredictionModelONNX:\n",
        "    def __init__(\n",
        "        self,\n",
        "        onnx_paths: list,\n",
        "        feat_centers: Optional[list] = None,\n",
        "        feat_scales: Optional[list] = None,\n",
        "    ):\n",
        "        assert len(onnx_paths) >= 1\n",
        "        self.models = []\n",
        "        for i, p in enumerate(onnx_paths):\n",
        "            center = None if feat_centers is None else feat_centers[i]\n",
        "            scale = None if feat_scales is None else feat_scales[i]\n",
        "            pm = PredictionModelONNX(p, feat_center=center, feat_scale=scale)\n",
        "            self.models.append(pm)\n",
        "\n",
        "    def reset_sequence(self, seq_ix: int):\n",
        "        for m in self.models:\n",
        "            m.reset_sequence(seq_ix)\n",
        "\n",
        "    def predict(self, data_point: DataPoint) -> Optional[np.ndarray]:\n",
        "        if not data_point.need_prediction:\n",
        "            # reset per-model sequence on first step\n",
        "            if data_point.step_in_seq in (0, 1):\n",
        "                for m in self.models:\n",
        "                    m.reset_sequence(data_point.seq_ix)\n",
        "            return None\n",
        "\n",
        "        preds = []\n",
        "        for m in self.models:\n",
        "            p = m.predict(data_point)\n",
        "            if p is None:\n",
        "                # unexpected; fallback zeros\n",
        "                # determine output size from first model outputs if possible\n",
        "                if len(self.models) > 0:\n",
        "                    out_size = len(self.models[0].predict(data_point) or [0, 0])\n",
        "                else:\n",
        "                    out_size = 2\n",
        "                p = np.zeros(out_size, dtype=np.float32)\n",
        "            preds.append(p.astype(np.float32))\n",
        "\n",
        "        preds = np.stack(preds, axis=0)  # (M, C)\n",
        "        mean_preds = preds.mean(axis=0)  # (C,)\n",
        "        return mean_preds"
      ],
      "metadata": {
        "id": "F_eHSoO4FVOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import onnxruntime as ort\n",
        "onnx_paths = sorted(glob.glob(\"./onxx_models/fold*.onnx\"))\n",
        "ensemble = EnsemblePredictionModelONNX(onnx_paths, None, None)"
      ],
      "metadata": {
        "id": "qmMqr3LMFYXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scorer = ScorerStepByStep(\"./competition_package/datasets/valid.parquet\")\n",
        "results = scorer.score(ensemble)"
      ],
      "metadata": {
        "id": "uUYjV_8wFaRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_XRyZsoSFd6l"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Добро пожаловать в Colab!",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}